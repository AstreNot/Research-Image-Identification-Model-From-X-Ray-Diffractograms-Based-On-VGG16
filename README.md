# Image Identification Model From X-Ray Diffractograms Based On VGG16
This project presents a deep learning approach for identifying material phases using X-ray diffractograms (XRD) images. Leveraging the power of the VGG16 convolutional neural network, the model classifies XRD patterns into specific material categories with the goal of automating phase recognition in material science. By converting diffractograms into images and fine-tuning a pre-trained VGG16 architecture, this project demonstrates how computer vision can enhance traditional material analysis, supporting faster and more scalable research workflows.
The repository includes the dataset preprocessing steps, model training scripts, evaluation metrics, and example predictions.

## ðŸ“¥ Data Collection
The dataset was generated by simulating X-ray diffractograms from crystal structure files in CIF format. These CIFs were collected from the Crystallography Open Database (COD), which serves as the primary source of structural data. Each CIF file contains atomic coordinates and lattice parameters for a unique crystalline phase, which were used to calculate theoretical diffraction patterns.

## ðŸ”— Data Sources
Primary Source:

1. Crystallography Open Database (COD)
An open-access repository of crystal structures, providing CIF files for thousands of inorganic, organic, and metal-organic compounds.
Note:
Only synthetic diffractograms generated from these CIFs are used in the project. No experimental or proprietary XRD measurements are included.

## ðŸ§¹ Data Preparation
Diffractogram Simulation:
CIF files were parsed to extract structural information.
Simulation of the diffractograms was carried out using the open-source xrayutilities library that computes peak positions and intensities based on Bragg's Law and structure factor calculations.
Peak intensity vs. 2Î¸ values were computed for Cu KÎ± radiation (Î» = 1.5406 Ã…).

Image Generation:
Simulated XRD patterns were plotted using matplotlib.
Each plot was saved as a standardized PNG image (224x224 pixels, black background, white lines) for CNN training.

Preprocessing:
Images were resized and normalized to meet VGG16 input requirements.
Data augmentation (rotation, contrast shift) was applied to increase dataset diversity.

Labeling & Organization:
Each image was labeled according to its crystal class or material group (e.g., cubic, tetragonal, orthorhombic).
A clean directory structure was maintained

Dataset Splitting:
Training: 70%
Validation: 20%
Test: 10%
